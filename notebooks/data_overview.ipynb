{"cells":[{"cell_type":"markdown","source":["## Overview of the relevant data objects and structures\n\n#### [Tweets](https://dev.twitter.com/overview/api/tweets)\n\n+ Relevant fields considered for this presentation: `tweet_id`, `user_id` and `text`\n+ Natively in `.json` format\n+ cf tweet sample\n\n#### JSON format\n\n+ Semi-structured data format\n+ [Databricks specific JSON format requirements](https://docs.databricks.com/spark/latest/data-sources/read-json.html)\n+ Python script to extract a collection of `.json` tweet files to a single `.json` file.\n\n\n#### [Spark Dataframes](https://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes)\n\n+ A DataFrame is a distributed collection of data organized into named columns\n+ Supports (domain-specific) DataFrame Operations and SQL queries\n\n\n#### [Spark table](https://docs.databricks.com/user-guide/tables.html)\n\n+ Tables are a simple way to make structured data available across an organization\n+ Tables are essentially Spark dataframe that are persisted in the Hive metastore (data warehouse)\n+ A user can query tables with Spark SQL or any of Apache Sparkâ€™s language APIs\n+ In Databricks, tables can be created from local files using the Data Import UI (_> table > Create Table > Local file_)\n+ In Databricks, supported source file formats for creating tables include `.json`, `.csv`, `.avro` and `.parquet`"],"metadata":{}}],"metadata":{"name":"data_overview","notebookId":3963252404083091},"nbformat":4,"nbformat_minor":0}
