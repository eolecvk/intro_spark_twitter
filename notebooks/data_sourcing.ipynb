{"cells":[{"cell_type":"markdown","source":["## Data sourcing\n\n### 0. Get tweets, format as single JSON, upload to Databricks\n\nI have made a sample tweet collection available [here](https://github.com/eolecvk/intro_spark_twitter/blob/master/data/tweets.json).\n\nThis tweet collection was generated:\n\n+ Using Twitter REST API ([doc](https://dev.twitter.com/rest/public)) to download tweets of interest; then,\n+ Using [this script](https://github.com/eolecvk/intro_spark_twitter/blob/master/utils/json_aggregator.py) to aggregate the ingested tweet collection as a single JSON file.\n\nOnce a properly formatted source file is available, one can simply upload it to Databricks as a Spark table _(Tables>Create Table>From file)_.  1\nSpark tables can then be easily queried/converted to Spark DataFrames for analysis.\n\n\n### 1. Create a DataFrame from a Spark Table"],"metadata":{}},{"cell_type":"code","source":["# Option_1: Using SQL query\ntweet_df_sql = sql(\"SELECT * FROM YOUR_TABLE_NAME\")\n\n# Option_2: Using sqlContext\ntweet_df_sqlContext = sqlContext.table(\"YOUR_TABLE_NAME\")"],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"data_sourcing","notebookId":3963252404083100},"nbformat":4,"nbformat_minor":0}
