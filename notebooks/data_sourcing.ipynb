{"cells":[{"cell_type":"markdown","source":["## Data sourcing\n\n### 0. Prior steps to create the dataset\n\n1. GET tweets using Twitter REST API ([doc](https://dev.twitter.com/rest/public))\n2. Aggregate tweets to this [single JSON source file](https://github.com/eolecvk/intro_spark_twitter/blob/master/data/tweets.json) with [this script](https://github.com/eolecvk/intro_spark_twitter/blob/master/utils/json_aggregator.py))\n3. Upload the source file to S3 (in this case with public READ access)\n\n### 1. Create a Spark table from source file stored in S3\n\nThe following function:\n\n+ Checks if the table exists; if not:\n+ Loads data from S3 to the Databricks FileSystem as JSON source file\n+ Creates a DataFrame using the JSON source file\n+ Saves the DataFrame to the Hive Metastore as Spark Table for persistence"],"metadata":{}},{"cell_type":"code","source":["SOURCE_URL = \"https://s3.amazonaws.com/XXXXXXXXXXXXXXXXXX\"\nTABLE_NAME = \"YOUR_TABLE_NAME\"\n\ndef createTable(tableName=TABLE_NAME, sourceURL=SOURCE_URL):\n    \"\"\"\n    Creates new Table based on the content of a json formated file\n    stored in S3 and publically accessible with URL\n    \"\"\"\n    import urllib2, json\n\n    # Test existence of table\n    table_exists = (\n      sql(\"SHOW TABLES\")\n      .filter(\"tableName = '{}'\".format(tableName))\n      .count()\n      )\n\n    if table_exists:\n        print(\"> Table `{}` already exists\".format(tableName))\n\n    if not table_exists:\n        print(\"> Table `{}` not found in metastore\".format(tableName))\n\n        # File handler from URL\n        print(\"> Loading data from {}\".format(sourceURL))\n        data = urllib2.urlopen(sourceURL)\n\n        # Create string from file content\n        json_str = ''.join([line for line in data])\n\n        # Load to hdfs\n        print(\"> Saving JSON file to FileSystem\")\n        dbutils.fs.put(\"/tmp/tweets.json\", json_str, True)\n\n        # Create new df from json file\n        print(\"> Creating new DataFrame from json file\")\n        new_df = sqlContext.read.json(\"/tmp/tweets.json\")\n\n        # Saving df as table for persistence\n        print(\"> Saving DataFrame as Table `{}`\".format(tableName))\n        new_df.write.saveAsTable(tableName)\n\ncreateTable()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### Check table created by querying it"],"metadata":{}},{"cell_type":"code","source":["# Option_1: Using SQL query\ntweet_df_sql = sql(\"SELECT * FROM {}\".format(TABLE_NAME))\n\n# Display\ntweet_df_sql.printSchema()\ntweet_df_sql.show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Option_2: Using sqlContext\ntweet_df_sqlContext = sqlContext.table(TABLE_NAME)\n\n# Display\ntweet_df_sqlContext.printSchema()\ntweet_df_sqlContext.show()"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"data_sourcing","notebookId":3963252404083100},"nbformat":4,"nbformat_minor":0}
